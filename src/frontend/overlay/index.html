<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Twitch Redeem Overlay</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: rgba(0, 0, 0, 0);
      -webkit-app-region: drag;
      width: 100vw;
      height: 100vh;
    }

    #overlay-container {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      pointer-events: none;
    }

    .overlay-item {
      position: absolute;
      background-repeat: no-repeat;
      background-size: contain;
      background-position: center;
    }

    .overlay-video, .overlay-gif {
      overflow: hidden;
    }
    
    video {
      width: 100%;
      height: 100%;
      object-fit: fill;
    }
    
    .chroma-key-filter {
      -webkit-backdrop-filter: contrast(1.5);
      backdrop-filter: contrast(1.5);
    }
    
    /* Red border styles */
    .border-container {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      border: 3px solid rgba(255, 0, 0, 0.6);
      box-sizing: border-box;
      pointer-events: none;
      z-index: 9999;
    }
    
    /* Toggle button for border visibility */
    #toggle-border {
      position: fixed;
      top: 5px;
      right: 5px;
      background-color: rgba(0, 0, 0, 0.5);
      color: white;
      border: none;
      border-radius: 3px;
      padding: 2px 5px;
      font-size: 10px;
      cursor: pointer;
      z-index: 10000;
      opacity: 0.3;
      transition: opacity 0.3s;
    }
    
    #toggle-border:hover {
      opacity: 1;
    }
  </style>
</head>
<body>
  <div id="overlay-container"></div>
  <div class="border-container" id="border-container"></div>

  <script>
    // Border visibility toggle
    const borderElement = document.getElementById('border-container');
    let borderVisible = true;
    
    // Initialize border to cover the entire viewport (including vertical monitors)
    function updateBorderSize() {
      borderElement.style.width = `${window.innerWidth}px`;
      borderElement.style.height = `${window.innerHeight}px`;
      console.log(`Updated border size: ${window.innerWidth}x${window.innerHeight}`);
    }
    
    // Update the border size initially and when the window is resized
    updateBorderSize();
    window.addEventListener('resize', updateBorderSize);
    
    
    // Cache to store media dimensions
    const mediaDimensions = new Map();
    
    // Listen for overlay display commands from main process
    window.electron.receive('display-overlay', (data) => {
      displayOverlayItem(data);
    });
    
    // Listen for cache clearing commands
    window.electron.receive('clear-cache', () => {
      clearLocalCache();
    });
    
    // Function to clear local cache of dimensions
    function clearLocalCache() {
      mediaDimensions.clear();
      console.log('Local media cache cleared');
    }
    
    // Function to apply chroma key via WebGL shaders
    function applyChromaKey(element, chromaKey, data) {
      if (!chromaKey) return;
      
      try {
        // Convert hex to rgb if needed
        let targetR, targetG, targetB;
        if (chromaKey.startsWith('#')) {
          targetR = parseInt(chromaKey.slice(1, 3), 16) / 255;
          targetG = parseInt(chromaKey.slice(3, 5), 16) / 255;
          targetB = parseInt(chromaKey.slice(5, 7), 16) / 255;
        } else if (chromaKey.startsWith('rgb')) {
          const match = chromaKey.match(/rgb\((\d+),\s*(\d+),\s*(\d+)\)/);
          if (match) {
            targetR = parseInt(match[1]) / 255;
            targetG = parseInt(match[2]) / 255;
            targetB = parseInt(match[3]) / 255;
          }
        }
        
        if (element.tagName === 'VIDEO') {
          // For videos we need to use a canvas with WebGL
          const videoContainer = element.parentElement;
          
          // Check if container exists
          if (!videoContainer) {
            console.error('Video container not found');
            return;
          }
          
          // Create a canvas for the WebGL rendering
          const canvas = document.createElement('canvas');
          canvas.style.position = 'absolute';
          canvas.style.top = '0';
          canvas.style.left = '0';
          canvas.style.width = '100%';
          canvas.style.height = '100%';
          canvas.style.objectFit = 'fill'; // Make canvas fill the container
          
          // Set actual canvas dimensions to match video
          const updateCanvasSize = () => {
            // Use the container dimensions rather than the video's natural dimensions
            canvas.width = videoContainer.clientWidth;
            canvas.height = videoContainer.clientHeight;
            console.log(`Canvas size updated to: ${canvas.width}x${canvas.height}`);
          };
          
          // Update size immediately if metadata already loaded
          if (element.videoWidth) {
            updateCanvasSize();
          }
          
          element.addEventListener('loadedmetadata', updateCanvasSize);
          
          // Get WebGL context
          const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
          if (!gl) {
            console.error('WebGL not supported');
            return;
          }
          
          // Create shader program
          const vertexShaderSource = `
            attribute vec2 a_position;
            attribute vec2 a_texCoord;
            varying vec2 v_texCoord;
            void main() {
              gl_Position = vec4(a_position, 0, 1);
              v_texCoord = a_texCoord;
            }
          `;
          
          const fragmentShaderSource = `
            precision mediump float;
            varying vec2 v_texCoord;
            uniform sampler2D u_image;
            uniform vec3 u_keyColor;
            uniform float u_similarity;
            uniform float u_smoothness;
            uniform float u_spill;
            
            void main() {
              vec4 color = texture2D(u_image, v_texCoord);
              
              // Calculate color difference - use a weighted distance that's more sensitive to green
              float colorDistance = length(color.rgb - u_keyColor);
              
              // Improved algorithm: weight green channel more heavily for green screens
              // Adjust these weights depending on your key color
              vec3 weights = vec3(0.3, 0.6, 0.1);
              float weightedDistance = 
                weights.r * abs(color.r - u_keyColor.r) +
                weights.g * abs(color.g - u_keyColor.g) +
                weights.b * abs(color.b - u_keyColor.b);
              
              // Combine both methods for better results
              float diff = mix(colorDistance, weightedDistance, 0.5);
              
              // Calculate alpha based on similarity and smoothness
              float alpha = smoothstep(u_similarity, u_similarity + u_smoothness, diff);
              
              // Spill suppression: reduce green in semi-transparent areas (for green screens)
              float spillValue = u_spill * (1.0 - alpha);
              vec3 spillReduction = color.rgb;
              
              // If it's a green screen, reduce green channel in semi-transparent areas
              if (u_keyColor.g > max(u_keyColor.r, u_keyColor.b)) {
                float greenExcess = color.g - ((color.r + color.b) * 0.5);
                if (greenExcess > 0.0) {
                  spillReduction.g -= max(0.0, greenExcess * spillValue);
                }
              }
              
              // Apply final color with alpha
              gl_FragColor = vec4(spillReduction, alpha);
            }
          `;
          
          // Create shaders
          const vertexShader = gl.createShader(gl.VERTEX_SHADER);
          gl.shaderSource(vertexShader, vertexShaderSource);
          gl.compileShader(vertexShader);
          
          const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
          gl.shaderSource(fragmentShader, fragmentShaderSource);
          gl.compileShader(fragmentShader);
          
          // Create program
          const program = gl.createProgram();
          gl.attachShader(program, vertexShader);
          gl.attachShader(program, fragmentShader);
          gl.linkProgram(program);
          gl.useProgram(program);
          
          // Set up buffers
          const positionBuffer = gl.createBuffer();
          const positions = [
            -1.0, -1.0,
             1.0, -1.0,
            -1.0,  1.0,
             1.0,  1.0
          ];
          gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
          gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);
          
          const positionLocation = gl.getAttribLocation(program, 'a_position');
          gl.enableVertexAttribArray(positionLocation);
          gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);
          
          // Modify the texture coordinates to stretch the video across the entire canvas
          const texCoordBuffer = gl.createBuffer();
          const texCoords = [
            0.0, 1.0,  // bottom left
            1.0, 1.0,  // bottom right
            0.0, 0.0,  // top left
            1.0, 0.0   // top right
          ];
          gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
          gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(texCoords), gl.STATIC_DRAW);
          
          const texCoordLocation = gl.getAttribLocation(program, 'a_texCoord');
          gl.enableVertexAttribArray(texCoordLocation);
          gl.vertexAttribPointer(texCoordLocation, 2, gl.FLOAT, false, 0, 0);
          
          // Create texture
          const texture = gl.createTexture();
          gl.bindTexture(gl.TEXTURE_2D, texture);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
          
          // Set uniforms
          const keyColorLocation = gl.getUniformLocation(program, 'u_keyColor');
          gl.uniform3f(keyColorLocation, targetR, targetG, targetB);
          
          // Get similarity and smoothness values from config or use defaults
          let similarity = 0.25;  // Default
          let smoothness = 0.1;   // Default
          
          // If we have explicit values in the data, use them
          if (data && data.chromaSimilarity !== undefined) {
            similarity = data.chromaSimilarity;
          }
          
          if (data && data.chromaSmoothness !== undefined) {
            smoothness = data.chromaSmoothness;
          }
        
          const similarityLocation = gl.getUniformLocation(program, 'u_similarity');
          gl.uniform1f(similarityLocation, similarity);
          
          const smoothnessLocation = gl.getUniformLocation(program, 'u_smoothness');
          gl.uniform1f(smoothnessLocation, smoothness);
          
          const spillLocation = gl.getUniformLocation(program, 'u_spill');
          gl.uniform1f(spillLocation, 0.7); // New spill reduction parameter
          
          // Let's make sure we append the canvas to the container and video is inside it
          // First, ensure video is visible inside the container
          element.style.display = 'block';
          element.style.visibility = 'hidden'; // Hide but keep layout
          element.style.position = 'absolute'; // Position it absolutely
          
          // Add canvas to the container
          videoContainer.appendChild(canvas);
          
          // Render function
          function render() {
            if (!element.paused && !element.ended) {
              // Make sure canvas size matches container size
              if (videoContainer.clientWidth !== canvas.width || videoContainer.clientHeight !== canvas.height) {
                updateCanvasSize();
              }
              
              // Update texture with new video frame
              gl.bindTexture(gl.TEXTURE_2D, texture);
              gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, element);
              
              // Set viewport to match canvas size
              gl.viewport(0, 0, canvas.width, canvas.height);
              
              // Draw
              gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
              
              // Request next frame
              requestAnimationFrame(render);
            }
          }
          
          // Start rendering as soon as we have video data
          element.addEventListener('play', () => {
            render();
          });
          
          if (!element.paused && !element.ended) {
            render(); // Start rendering immediately if video is already playing
          }
          
          // Enable alpha blending
          gl.enable(gl.BLEND);
          gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);
          
          console.log(`Applied WebGL chroma key for video: RGB(${targetR*255}, ${targetG*255}, ${targetB*255})`);
        } else {
          // For images/gifs - use the default approach with CSS for now
          // But we could use a similar WebGL approach if needed
          element.classList.add('chroma-key-element');
          
          // Apply a simple blend mode for images
          element.style.backgroundColor = chromaKey;
          element.style.backgroundBlendMode = 'screen';
          console.log(`Applied CSS chroma key for image: ${chromaKey}`);
        }
      } catch (err) {
        console.error('Error applying chroma key:', err);
      }
    }
    
    // Function to get the natural dimensions of media
    function getMediaDimensions(src, type) {
      return new Promise((resolve) => {
        // Check cache first
        if (mediaDimensions.has(src)) {
          resolve(mediaDimensions.get(src));
          return;
        }
        
        if (type === 'video') {
          const video = document.createElement('video');
          video.onloadedmetadata = () => {
            const dimensions = {
              width: video.videoWidth,
              height: video.videoHeight
            };
            mediaDimensions.set(src, dimensions);
            resolve(dimensions);
          };
          video.onerror = () => resolve(null);
          video.src = src;
        } else {
          const img = new Image();
          img.onload = () => {
            const dimensions = {
              width: img.naturalWidth,
              height: img.naturalHeight
            };
            mediaDimensions.set(src, dimensions);
            resolve(dimensions);
          };
          img.onerror = () => resolve(null);
          img.src = src;
        }
      });
    }

    async function displayOverlayItem(data) {
      const container = document.getElementById('overlay-container');
      let item;
      
      // Position coordinates (ensure they're relative to the current window)
      const xPos = data.x !== undefined ? data.x : 0;
      const yPos = data.y !== undefined ? data.y : 0;
      
      // Get window dimensions for positioning and scaling
      const windowWidth = window.innerWidth;
      const windowHeight = window.innerHeight;
      
      // Log positioning info
      console.log(`Displaying overlay at position: x=${xPos}, y=${yPos}`);
      console.log(`Window dimensions: ${windowWidth}x${windowHeight}`);
      
      // Handle special fullscreen case
      const isFullscreen = (data.width === windowWidth && data.height === windowHeight) || 
                           (data.width === 1920 && data.height === 1080 && xPos === 0 && yPos === 0);
      
      // Calculate dimensions
      let finalWidth, finalHeight;
      
      if (isFullscreen) {
        // For fullscreen intent, make it match window exactly
        finalWidth = windowWidth;
        finalHeight = windowHeight;
        console.log("Using fullscreen mode");
      } else if (data.width && data.height) {
        // Use provided dimensions
        finalWidth = data.width;
        finalHeight = data.height;
        
        // If media is too large for the screen, scale it down proportionally
        if (finalWidth > windowWidth || finalHeight > windowHeight) {
          const widthRatio = windowWidth / finalWidth;
          const heightRatio = windowHeight / finalHeight;
          const ratio = Math.min(widthRatio, heightRatio);
          
          finalWidth = Math.floor(finalWidth * ratio);
          finalHeight = Math.floor(finalHeight * ratio);
          console.log(`Scaled down to: ${finalWidth}x${finalHeight}`);
        }
      } else {
        // If no dimensions are specified, try to get natural media dimensions
        const naturalSize = await getMediaDimensions(data.path, data.type);
        if (naturalSize) {
          finalWidth = naturalSize.width;
          finalHeight = naturalSize.height;
          
          // If media is too large for the screen, scale it down
          if (finalWidth > windowWidth || finalHeight > windowHeight) {
            const widthRatio = windowWidth / finalWidth;
            const heightRatio = windowHeight / finalHeight;
            const ratio = Math.min(widthRatio, heightRatio);
            
            finalWidth = Math.floor(finalWidth * ratio);
            finalHeight = Math.floor(finalHeight * ratio);
            console.log(`Using natural size scaled: ${finalWidth}x${finalHeight}`);
          }
        } else {
          // Fallback if dimensions can't be determined
          finalWidth = windowWidth / 2;
          finalHeight = windowHeight / 2;
          console.log(`Using fallback dimensions: ${finalWidth}x${finalHeight}`);
        }
      }
      
      // Ensure item stays within viewport bounds
      const finalXPos = Math.min(Math.max(0, xPos), windowWidth - finalWidth);
      const finalYPos = Math.min(Math.max(0, yPos), windowHeight - finalHeight);
      
      console.log(`Final position and size: x=${finalXPos}, y=${finalYPos}, w=${finalWidth}, h=${finalHeight}`);
      
      if (data.type === 'video') {
        // Create a video element for MP4 files
        const videoContainer = document.createElement('div');
        videoContainer.className = 'overlay-item overlay-video';
        videoContainer.style.left = `${finalXPos}px`;
        videoContainer.style.top = `${finalYPos}px`;
        videoContainer.style.width = `${finalWidth}px`;
        videoContainer.style.height = `${finalHeight}px`;
        
        const video = document.createElement('video');
        video.autoplay = true;
        video.loop = false;
        // Allow sound to play by not setting muted=true
        video.muted = false;
        video.volume = data.volume !== undefined ? data.volume : 1.0; // Add volume control
        
        // IMPORTANT: First add video to container, THEN add container to DOM
        videoContainer.appendChild(video);
        container.appendChild(videoContainer);
        
        // Now set the src to start loading the video
        video.src = data.path;
        
        // Only AFTER the video is in the DOM, apply chroma key if specified
        if (data.chromaKey) {
          // Ensure video has a parent container before applying chroma key
          console.log('Applying chroma key, video parent:', video.parentElement);
          setTimeout(() => {
            // Add a small delay to ensure DOM is updated
            applyChromaKey(video, data.chromaKey, data);
          }, 0);
        }
        
        // Auto-remove after duration or when video ends
        const removeVideo = () => {
          if (videoContainer && videoContainer.parentNode) {
            videoContainer.parentNode.removeChild(videoContainer);
          }
        };
        
        video.onended = removeVideo;
        setTimeout(removeVideo, data.duration);
        
        item = videoContainer;
      } else {
        // Create div for GIFs and images
        item = document.createElement('div');
        item.className = `overlay-item overlay-${data.type}`;
        
        // Position the item
        item.style.left = `${finalXPos}px`;
        item.style.top = `${finalYPos}px`;
        item.style.width = `${finalWidth}px`;
        item.style.height = `${finalHeight}px`;
        
        // Set the background image
        item.style.backgroundImage = `url('${data.path}')`;
        
        // Apply chroma key if specified
        if (data.chromaKey) {
          applyChromaKey(item, data.chromaKey, data);
        }
        
        // Add to container
        container.appendChild(item);
        
        // Remove after duration
        setTimeout(() => {
          if (item && item.parentNode) {
            item.parentNode.removeChild(item);
          }
        }, data.duration);
      }
    }
    
    // Listen for border toggle commands from main process
    window.electron.receive('toggle-border', (visible) => {
      borderVisible = visible;
      borderElement.style.display = borderVisible ? 'block' : 'none';
      toggleButton.textContent = borderVisible ? 'Hide Border' : 'Show Border';
      
      // Update border size on toggle
      if (borderVisible) {
        updateBorderSize();
      }
    });
  </script>
</body>
</html>